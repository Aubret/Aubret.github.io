---
title: Deep reinforcement learning of skills for multi-agents coordination.
layout: default
---
### Introduction
In reinforcement learning, an agent learns by trials and errors to maximize the expectation of rewards received while acting in his environment. In a multi-agent scenario, some tasks imply that multiple agents have to cooperate ; yet, despite novel advances in deep reinforcement learning, it is known to be difficult to synchronize the agents, particularly when the number of agents is high. Communication is an efficient way to synchronize agents, however actual models only includes observations into their communication and consider scenarios with few agents. To adress those issues, we want to take advantage of recent works on intrinsic motivation.

At first, we want our agents to be able to communicate their intentions in addition to their observations, to do so, they have to learn a representation of their skills. As a second step, our goal is that our agents learn to choose what to communicate, when and to whom communicate it.


### Papers

Aubret, A., Matignon, L., Hassas, S.: ELSIM: End-to-end learning of reusable skills
through intrinsic motivation. ECML-PKDD 2020

Aubret, A., Matignon, L., Hassas, S.: ELSIM: End-to-end learning of reusable skills
through intrinsic motivation. ICML 2020 Workshop LifelongML

Aubret, A., Matignon, L., Hassas, S.: A survey on intrinsic motivation in reinforcement learning. arXiv
preprint arXiv:1908.06976 (2019)

Aubret, A., Matignon, L., Hassas, S.: Étude de la motivation intrinsèque en apprentissage par renforce-
ment (JFPDA 2019).




### Project participants

Name : AUBRET Arthur  
Co-director : MATIGNON Laetitia  
Director : HASSAS Salima  


### Contact

LIRIS  
Building Nautibus  
Université Claude Bernard Lyon 1  
43 Boulevard du 11 Novembre 1918  
69622 Villeurbanne Cedex  
arthur.aubret@univ-lyon1.fr  
