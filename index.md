My objective is to understand the fundamental learning mechanisms that underpin the development of high-level visual representations and behaviors in humans and machines. My approach is to construct bio-inspired models based on powerful machine learning approaches; this includes self-supervised representation learning, intrinsic motivation, hierarchical reinforcement learning. I currently work as a postdoctoral researcher at the Frankfurt Institute for Advanced Studies (FIAS). Below is my list of papers:

Feel free to reach out if you wish to talk !

### Postdoc, Frankfurt Institute for Advanced Studies: Toddler-inspired object representation learning

Aubret, Arthur and Jochen Triesch. Do vision models perceive objects like toddlers ? In ICLR Blogposts 2025. [temporary link](https://aubret.github.io/2025/blog/toddlers-vs-vismodels/)

Aubret, Arthur, Céline Teulière, and Jochen Triesch. Seeing the Whole in the Parts in Self-Supervised Representation Learning. Under review. [paper](https://arxiv.org/pdf/2501.02860)

Zhengyang Yu, Aubret, Arthur, Marcel C Raabe, Jane Yang, Chen Yu, and Jochen Triesch. Active gaze behavior boosts self-supervised object learning. Under review. [paper](https://arxiv.org/pdf/2411.01969)

Aubret, A.*, Schaumlöffel, T.*, Roig, G., & Triesch, J. (2025). Human Gaze Boosts Object-Centered Representation Learning. Under review. [paper](https://arxiv.org/pdf/2501.02966)

Aubret, A., Teulière, C., & Triesch, J. (2024). Self-supervised visual learning from interactions with objects. The European Conference on Computer Vision, 2024. [github](https://github.com/trieschlab/AASSL), [paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/09526.pdf)

Aubret, A.*, Schaumlöffel, T.*, Roig, G., & Triesch, J. (2024). Learning Object Semantic Similarity with Self-Supervision. In 2024 IEEE International Conference on Development and Learning. IEEE. [paper](https://arxiv.org/pdf/2405.05143)
<!-- [github to be coming] #(https://github.com/neuroai-arena/ObjectSemanticSimilarity) -->

Ernst, M. R., López, F. M., Aubret, A., Fleming, R. W., & Triesch, J. (2024). Self-Supervised Learning of Color Constancy. In 2024 IEEE International Conference on Development and Learning. IEEE. [github](https://github.com/trieschlab/ColorConstancyLearning), [paper](https://arxiv.org/pdf/2404.08127)

Schaumlöffel, T.*, Aubret, A.*, Roig, G., & Triesch, J. (2023, November). Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic Play. In 2023 IEEE International Conference on Development and Learning. IEEE. [paper](https://arxiv.org/pdf/2312.04118)
<!-- [github to be coming]#(https://github.com/neuroai-arena/ToddlerVisionLearning) -->

### Postdoc, Clermont Ferrand Pascal institute: Toddler-inspired object representation learning

Aubret, A.*, Ernst, M. R.*, Teulière, C., & Triesch, J. Time to augment self-supervised visual representation learning. In The Eleventh International Conference on Learning Representations, 2023. [paper](https://openreview.net/forum?id=o8xdgmwCP8l)

Arthur Aubret, Céline Teulière, and Jochen Triesch. Embodied vision for learning object representations. Joint IEEE International Conference on Development and Learning (ICDL), 2022. [paper](https://hal.science/hal-03838291v1/file/ICDL_2022.pdf)

Arthur Aubret, Céline Teulière, and Jochen Triesch. Toddler-inspired learning induces hierarchical object representations. 3th Sensorimotor Interaction, Language and Embodiment of Symbols (SMILES) workshop at ICDL, 2022. [paper](https://hal.science/hal-03838312/file/Smiles_workshop.pdf)

Aubret, A., Lefort, M., Teulière, C., Matignon, L., Hassas, S., & Triesch, J. Compressed information is all you need: unifying intrinsic motivations and representation learning. In NeurIPS 2022 Workshop on Information-Theoretic Principles in Cognitive Systems, 2022. [paper](https://openreview.net/pdf?id=d3orKrYcLqE)

Dominik Mattern, Francisco M. López, Markus R. Ernst, Arthur Aubret, and Jochen Triesch. Mimo: A multi-modal infant model for studying cognitive development in humans and ais. Joint IEEE International Conference on Development and Learning (ICDL), 2022. [paper](https://arxiv.org/pdf/2312.04318)

### Ph.D, Lyon, LIRIS: Learning increasingly complex skills through deep reinforcement learning using intrinsic motivation

Aubret, A., Matignon, L., & Hassas, S. (2023). An information-theoretic perspective on intrinsic motivation in reinforcement learning: a survey. Entropy, 2023. [paper](https://www.mdpi.com/1099-4300/25/2/327/pdf)

Aubret, A., Matignon, L., Hassas, S.: DisTop: Discovering a Topological representation to learn diverse and rewarding skills. IEEE Transactions on Cognitive and Developmental Systems 2023. [paper](https://hal.science/hal-03352684v1/file/DisTop.pdf)

Arthur Aubret, Laëtitia Matignon, Salima Hassas: ELSIM: End-to-End Learning of Reusable Skills Through Intrinsic Motivation. ECML/PKDD (2) 2020: 541-556. [paper](https://arxiv.org/pdf/2006.12903)

Aubret, A., Matignon, L., Hassas, S.: ELSIM: End-to-end learning of reusable skills through intrinsic motivation. ICML 2020 Workshop LifelongML. [paper](https://arxiv.org/pdf/2006.12903)

Aubret, A., Matignon, L., Hassas, S.: Étude de la motivation intrinsèque en apprentissage par renforcement. Journées Francophones Planification, Décision et Apprentissage, 2019. [paper](https://www.mdpi.com/1099-4300/25/2/327/pdf)

### Link thesis

[Thesis](./these.pdf)



### Contact
Mail: ajp.aubret@gmail.com

Twitter: @Arthur_Aubret
